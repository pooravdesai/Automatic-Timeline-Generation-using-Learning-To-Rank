{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBseDoG5Pd9Y"
   },
   "outputs": [],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLWJ2J5oPmX6"
   },
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dW9e2ibmPoC-"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "DATA=[]\n",
    "Dict_date={}\n",
    "punctuations = '''!()-[]{};:'\"\\|,<>./?@#$%^&*_~'''\n",
    "import datetime\n",
    "for i in range(1,150):\n",
    "  \n",
    "  URL = 'https://www.hindustantimes.com/search?q=nirbhaya&pageno='+str(i)\n",
    "  page = requests.get(URL)\n",
    "\n",
    "  soup = BeautifulSoup(page.content, 'html.parser')\n",
    "  job_elems=soup.findAll(name='div',attrs={'class':\"media-heading headingfour\"})\n",
    "  for job_elem in job_elems:\n",
    "    title_elem = job_elem.find('a')\n",
    "    URL=(title_elem['href'])\n",
    "    page1 = requests.get(URL)\n",
    "    soup1 = BeautifulSoup(page1.content, 'html.parser')\n",
    "    job_elems1=soup1.findAll(name='script',attrs={'type':\"application/ld+json\"})  \n",
    "        #print(json.loads(\"\".join(soup.find(\"script\", {\"type\":\"application/ld+json\"}).contents)))\n",
    "    try:\n",
    "      x=(json.loads(\"\".join(job_elems1[2].contents)))\n",
    "      headline=((x.get(\"headline\")))\n",
    "      \n",
    "      no_punct = \"\"\n",
    "      for char in headline:\n",
    "        if char not in punctuations:\n",
    "          no_punct = no_punct + char\n",
    "      headline=no_punct\n",
    "    # file2 = open(\"D:\\\\Text\\\\\"+headline+\".txt\",\"w+\",encoding=\"utf-8\") \n",
    "      file2 = open(\"drive/My Drive/IR Project DATA/News Articles/\"+headline+\".txt\",\"w+\",encoding=\"utf-8\") \n",
    "        \n",
    "      print(x.get(\"headline\"))\n",
    "      file2.write(x.get(\"articleBody\"))\n",
    "              \n",
    "      file2.close() \n",
    "      DATA.append(x.get(\"articleBody\"))    \n",
    "      #file1=open(\"D:\\\\Text1\\\\\"+headline+\".txt\",\"w+\",encoding=\"utf-8\")\n",
    "      file1=open(\"drive/My Drive/IR Project DATA/Ground Truth/\"+headline+\".txt\",\"w+\",encoding=\"utf-8\")\n",
    "      \n",
    "      file1.write(x.get(\"dateModified\")+\" \"+x.get(\"headline\"))\n",
    "      file1.close()\n",
    "      doc_date=x.get(\"dateModified\")\n",
    "      doc_date = doc_date[:doc_date.split(\" \")[0].rfind(\"+\")]\n",
    "      d = datetime.datetime.strptime(doc_date, \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "\n",
    "      Dict_date.update({x.get(\"headline\"):d})\n",
    "    except:\n",
    "      pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data Scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
