{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9OQaMts5MY-C"
   },
   "source": [
    "# Listwise Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fqdPgBNIgdy"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtCPXFvhlaMl"
   },
   "outputs": [],
   "source": [
    "class Listwise(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super(Listwise, self).__init__();\n",
    "    ''' Elman RNN for overall context of the set of document vectors that needs to be chronologically ordered. '''\n",
    "    self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "    \n",
    "    ''' MLP that computes the final scores for each document vector. '''\n",
    "    self.mlp = nn.Sequential(\n",
    "        nn.Linear(2*hidden_size, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "  \n",
    "  def forward(self, input_doc_vectors):\n",
    "    ''' input_doc_vectors: a list of document vectors(tensors) that needs to be chronologically arranged. '''\n",
    "    outputs = []\n",
    "    for i, doc_vec in enumerate(input_doc_vectors):\n",
    "      # print(\"doc vec shape: \", doc_vec.shape)\n",
    "      doc_vec_in = doc_vec.view(1,1,doc_vec.shape[0])\n",
    "      # print(\"doc vec in shape: \", doc_vec_in.shape)\n",
    "      if i == 0:\n",
    "        output, h_next = self.rnn(doc_vec_in)\n",
    "      else:\n",
    "        output, h_next = self.rnn(doc_vec_in, h_next)\n",
    "      outputs.append(output.view(output.shape[2]))\n",
    "    \n",
    "    final_hidden_state = h_next.view(h_next.shape[2])\n",
    "    # print(\"final hidden state shape: \", final_hidden_state.shape)\n",
    "    doc_vec_scores = []\n",
    "\n",
    "    for out in outputs:\n",
    "      mlp_in = torch.cat([out, final_hidden_state]).unsqueeze(0)\n",
    "      doc_vec_score = self.mlp(mlp_in)[0]\n",
    "      doc_vec_scores.append(doc_vec_score)\n",
    "    \n",
    "    doc_vec_scores_tensor = torch.stack(doc_vec_scores)\n",
    "    return doc_vec_scores_tensor\n",
    "  \n",
    "  def train(self, X, y, optimizer, device, epochs=10, batch_size=20):\n",
    "    batch_no = 1\n",
    "    for ep in range(epochs):\n",
    "      print(\"epoch no: \", ep)\n",
    "      losses = []\n",
    "      for i, (doc_vec_set, target) in enumerate(zip(X, y)):\n",
    "        doc_vec_tensor_set = [torch.from_numpy(x).float().to(device) for x in doc_vec_set]\n",
    "        target_tensor = torch.tensor(target).float().to(device)\n",
    "        \n",
    "        predicted_scores_tensor = self(doc_vec_tensor_set)\n",
    "        # print(target_tensor.view(target_tensor.shape[0], 1).shape, predicted_scores_tensor.shape)\n",
    "        \n",
    "        loss = nn.MSELoss()(predicted_scores_tensor, target_tensor.view(target_tensor.shape[0], 1))\n",
    "        losses.append(loss)\n",
    "        if (i+1) % batch_size == 0:\n",
    "          optimizer.zero_grad()\n",
    "          mean_loss = torch.stack(losses).mean()\n",
    "          mean_loss.backward()\n",
    "          optimizer.step()\n",
    "          losses = []\n",
    "          print(\"batch no. \"+str(batch_no)+\" mean loss: \", mean_loss)\n",
    "          batch_no += 1\n",
    "  \n",
    "  def inference(self, X):\n",
    "    ''' X: a list in which each element is a list of document vectors that needs to be chronologically arranged. '''\n",
    "    outs = []\n",
    "    for doc_vec_set in X:\n",
    "      doc_vec_tensor_set = [torch.from_numpy(x).float().to(device) for x in doc_vec_set]\n",
    "      predicted_scores_tensor = self(doc_vec_tensor_set)\n",
    "      # print(predicted_scores_tensor, predicted_scores_tensor.shape)\n",
    "      predicted_order_of_documents = predicted_scores_tensor.argsort()\n",
    "      outs.append(predicted_order_of_documents.detach().cpu().numpy())\n",
    "    if len(outs) == 1:  return outs[0]\n",
    "    return outs\n",
    "\n",
    "def save_model(path, model):\n",
    "  torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(path, model):\n",
    "  state_dict = torch.load(path)\n",
    "  model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzdOGpGQ5E4a"
   },
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "  with open(path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "  return data\n",
    "\n",
    "def save_pickle(path, data):\n",
    "  with open(path, \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_FERgwJ52O4"
   },
   "outputs": [],
   "source": [
    "path_to_ir = \"/content/drive/My Drive/IR Project DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyelkTWb5taS"
   },
   "outputs": [],
   "source": [
    "dataset = load_pickle(os.path.join(path_to_ir, \"XXX\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Fb5tIrSo6AJX",
    "outputId": "4c6486e5-5dc4-4d5c-bc14-bba7c1871e01",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = dataset\n",
    "print(len(X))\n",
    "print(X[0][0].shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4jfv-vyRUYO"
   },
   "outputs": [],
   "source": [
    "Xtrain, ytrain = X[:1500], y[:1500]\n",
    "Xtest, ytest = X[1500:], y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AWuHaUZK4lo_",
    "outputId": "92d37dd8-f609-4d63-f481-6a573abe1724"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "input_size=X[0][0].shape[0]\n",
    "hidden_size=input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiHKTsOZSozb"
   },
   "outputs": [],
   "source": [
    "model = Listwise(input_size=input_size, hidden_size=hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uS9oV_5T75AM",
    "outputId": "82605248-8e63-433f-8d9e-986980bec511",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train(Xtrain, ytrain, optim.Adam(model.parameters(), lr=0.001), device, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5tKZsIEcd8y"
   },
   "outputs": [],
   "source": [
    "save_model(os.path.join(path_to_ir, \"model1\"), model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "List wise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
