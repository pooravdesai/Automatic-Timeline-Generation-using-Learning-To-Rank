{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaNaAGrTUvP1"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CvdyR6ZU-iX"
   },
   "outputs": [],
   "source": [
    "num_classes = 200\n",
    "input_size = 200  \n",
    "hidden_size = 200 \n",
    "batch_size = 1   \n",
    "sequence_length = 1  \n",
    "num_layers = 1  \n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Model, self).__init__()\n",
    "    self.rnn = nn.RNN(input_size=input_size,\n",
    "                          hidden_size=hidden_size, batch_first=True)\n",
    "\n",
    "  def forward(self, hidden, x):\n",
    "        \n",
    "    x = x.view(batch_size, sequence_length, input_size)\n",
    "\n",
    "        \n",
    "    out, hidden = self.rnn(x, hidden)\n",
    "    return hidden, out.view(-1, num_classes)\n",
    "\n",
    "  def init_hidden(self):\n",
    "        \n",
    "    return Variable(torch.zeros(num_layers, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDB_xf10VFrh"
   },
   "outputs": [],
   "source": [
    "my_vecs=[]\n",
    "inputs = Variable(torch.Tensor(vectors))\n",
    "model = Model()\n",
    "hidden = model.init_hidden()\n",
    "for input in (inputs):\n",
    "      \n",
    "  hidden, output = model(hidden, input)\n",
    "  my_vecs.append(output)\n",
    "\n",
    "vecs=[]\n",
    "for item in my_vecs:\n",
    "\n",
    "  x=list(hidden.detach().numpy()[0][0])\n",
    "  y=list(item.detach().numpy()[0])\n",
    "  vec=(x+y)\n",
    "  vecs.append(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1USUJTcMVKCQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "layers = []\n",
    "layers.append(nn.Linear(400, 64))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(64, 64))\n",
    "layers.append(nn.ReLU())\n",
    "\n",
    "layers.append(nn.Linear(64,1))\n",
    "\n",
    "net = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnIxG1eaVP3e"
   },
   "outputs": [],
   "source": [
    "for item in vecs:\n",
    "  i = torch.from_numpy(np.array(item))\n",
    "  score=net(i)\n",
    "  print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtCPXFvhlaMl"
   },
   "outputs": [],
   "source": [
    "class Listwise(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super(Listwise, self).__init__();\n",
    "    self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "    self.mlp = nn.Sequential(\n",
    "        nn.Linear(2*hidden_size, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "  \n",
    "  def forward(self, input_doc_vectors):\n",
    "    outputs = []\n",
    "    for i, doc_vec in enumerate(input_doc_vectors):\n",
    "      print(\"doc vec shape: \", doc_vec.shape)\n",
    "      doc_vec_in = doc_vec.view(1,1,doc_vec.shape[0])\n",
    "      print(\"doc vec in shape: \", doc_vec_in.shape)\n",
    "      if i == 0:\n",
    "        output, h_next = self.rnn(doc_vec_in)\n",
    "      else:\n",
    "        output, h_next = self.rnn(doc_vec_in, h_next)\n",
    "      outputs.append(output.view(output.shape[2]))\n",
    "    \n",
    "    final_hidden_state = h_next.view(h_next.shape[2])\n",
    "    print(\"final hidden state shape: \", final_hidden_state.shape)\n",
    "    doc_vec_scores = []\n",
    "\n",
    "    for out in outputs:\n",
    "      mlp_in = torch.cat([out, final_hidden_state]).unsqueeze(0)\n",
    "      doc_vec_score = self.mlp(mlp_in)[0]\n",
    "      doc_vec_scores.append(doc_vec_score)\n",
    "    \n",
    "    doc_vec_scores_tensor = torch.stack(doc_vec_scores)\n",
    "    return doc_vec_scores_tensor\n",
    "  \n",
    "  def train(self, X, y, optimizer, epochs=10, batch_size=20, device='cpu'):\n",
    "    for ep in range(epochs):\n",
    "      print(\"epoch no: \", ep)\n",
    "      losses = []\n",
    "      for i, (doc_vec_set, target) in enumerate(zip(X, y)):\n",
    "        doc_vec_tensor_set = [torch.from_numpy(x).float().to(device) for x in doc_vec_set]\n",
    "        target_tensor = torch.tensor(target).float().to(device)\n",
    "        predicted_scores_tensor = self(doc_vec_tensor_set)\n",
    "        \n",
    "        loss = nn.MSELoss()(predicted_scores_tensor, target_tensor)\n",
    "        losses.append(loss)\n",
    "        if (i+1) % batch_size == 0:\n",
    "          optimizer.zero_grad()\n",
    "          mean_loss = torch.stack(losses).mean()\n",
    "          mean_loss.backward()\n",
    "          optimizer.step()\n",
    "          losses = []\n",
    "  \n",
    "  def inference(self, X):\n",
    "    for doc_vec_set in X:\n",
    "      doc_vec_tensor_set = [torch.from_numpy(x).float().to(device) for x in doc_vec_set]\n",
    "      predicted_scores_tensor = self(doc_vec_tensor_set)\n",
    "      predicted_order_of_documents = predicted_scores_tensor.argsort()\n",
    "      return predicted_order_of_documents.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzdOGpGQ5E4a"
   },
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "  with open(path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "  return data\n",
    "\n",
    "def save_pickle(path, data):\n",
    "  with open(path, \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_FERgwJ52O4"
   },
   "outputs": [],
   "source": [
    "path_to_ir = \"/content/drive/My Drive/IR Project DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyelkTWb5taS"
   },
   "outputs": [],
   "source": [
    "dataset = load_pickle(os.path.join(path_to_ir, \"Train_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Fb5tIrSo6AJX",
    "outputId": "bb2e92f8-440e-4aeb-cfaf-7290a51c4fc0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = dataset\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWuHaUZK4lo_"
   },
   "outputs": [],
   "source": [
    "input_size=2\n",
    "hidden_size=2\n",
    "model = Listwise(input_size=input_size, hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uS9oV_5T75AM",
    "outputId": "8c6d9116-7597-46b1-fa43-55ab3b392765"
   },
   "outputs": [],
   "source": [
    "x1 = [np.array([1.,2.]), np.array([1.,3.]), np.array([2.,6.])]\n",
    "y1 = [2.,1.,3.]\n",
    "model.train([x1], [y1], optim.Adam(model.parameters(), lr=0.001), batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "List wise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
